{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIXqWatYyjvlmtee/PsiLH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chamindu002/chamindu002/blob/main/sanction_textual_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LZaDtSjy4N4",
        "outputId": "35e87351-3efa-41ea-d455-2d1a5b682e43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/235.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install unidecode -q\n",
        "!pip install torch pandas openpyxl -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import re\n",
        "from unidecode import unidecode\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "print(\"Drive mounted.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mSyUidHMnW4",
        "outputId": "6f160149-7316-4dde-b32e-c420be0b0328"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "Drive mounted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Model Classes"
      ],
      "metadata": {
        "id": "-rE5S6P9MuLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NameEncoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=96, hidden=192):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden*2, 192)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embed(x)\n",
        "        out, _ = self.lstm(x)\n",
        "        out = out[:, -1, :]  # last timestep\n",
        "        out = torch.tanh(self.fc(out))\n",
        "        return out\n",
        "\n",
        "class Siamese(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.encoder = NameEncoder(vocab_size)\n",
        "        self.cosine = nn.CosineSimilarity(dim=1)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        v1 = self.encoder(x1)\n",
        "        v2 = self.encoder(x2)\n",
        "        return self.cosine(v1, v2)"
      ],
      "metadata": {
        "id": "6z593m6bMrgn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the Model**"
      ],
      "metadata": {
        "id": "UdfBC8wdM2Ai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "load_path = \"/content/drive/My Drive/Research/Data/siamese_name_matcher_best_intials.pt\"\n",
        "\n",
        "print(f\"Loading model from: {load_path}\")\n",
        "checkpoint = torch.load(load_path, map_location=device)\n",
        "\n",
        "# Restore config\n",
        "char2idx = checkpoint['char2idx']\n",
        "max_len = checkpoint['max_len']\n",
        "vocab_size = checkpoint['vocab_size']\n",
        "\n",
        "model = Siamese(vocab_size).to(device)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "print(\"✅ Model loaded!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_i8vBq6MyZt",
        "outputId": "ff115b11-0c46-43da-d755-8cccf37eea4c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from: /content/drive/My Drive/Research/Data/siamese_name_matcher_best_intials.pt\n",
            "✅ Model loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Helper Functions"
      ],
      "metadata": {
        "id": "aGb211hWM81E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_and_transliterate(s):\n",
        "    if s is None or pd.isna(s): return \"\"\n",
        "    s = unidecode(str(s))\n",
        "    s = s.lower().strip()\n",
        "    s = re.sub(r\"[^a-z\\s\\.]\", \" \", s)  # Keep dots for initials\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    return s.strip()\n",
        "\n",
        "def encode_name(name):\n",
        "    name = normalize_and_transliterate(name)\n",
        "    seq = [char2idx.get(c, char2idx[\"<UNK>\"]) for c in name[:max_len]]\n",
        "    seq += [char2idx[\"<PAD>\"]] * (max_len - len(seq))\n",
        "    return torch.tensor([seq], dtype=torch.long).to(device)\n",
        "\n",
        "def get_similarity(name1, name2):\n",
        "    if not name1 or not name2: return 0.0\n",
        "    t1 = encode_name(name1)\n",
        "    t2 = encode_name(name2)\n",
        "    with torch.no_grad():\n",
        "        score = model(t1, t2).item()\n",
        "    return score\n",
        "\n",
        "def extract_birth_year(birth_date):\n",
        "    \"\"\"Extract set of possible birth years from string.\"\"\"\n",
        "    if pd.isna(birth_date) or not str(birth_date).strip():\n",
        "        return set()\n",
        "    bd = str(birth_date).strip()\n",
        "    years = set()\n",
        "\n",
        "    # Full date: 1978-04-28 -> 1978\n",
        "    if re.match(r'^\\d{4}-\\d{2}-\\d{2}$', bd):\n",
        "        years.add(int(bd[:4]))\n",
        "\n",
        "    # Year only: 1973\n",
        "    elif re.match(r'^\\d{4}$', bd):\n",
        "        years.add(int(bd))\n",
        "\n",
        "    # Range: 1970-1980\n",
        "    elif '-' in bd:\n",
        "        parts = bd.split('-')\n",
        "        if len(parts) == 2 and parts[0].isdigit() and parts[1].isdigit():\n",
        "            start, end = int(parts[0]), int(parts[1])\n",
        "            years.update(range(start, end+1))\n",
        "\n",
        "    # Multiple: 1970, 1972 -> {1970,1972}\n",
        "    elif ',' in bd:\n",
        "        for y in bd.split(','):\n",
        "            y = y.strip()\n",
        "            if y.isdigit() and len(y)==4:\n",
        "                years.add(int(y))\n",
        "\n",
        "    return years\n",
        "\n",
        "def fields_match(cust_val, src_val, field):\n",
        "    \"\"\"Check if fields match (exact, ignoring case, if provided).\"\"\"\n",
        "    if pd.isna(cust_val) or not str(cust_val).strip():\n",
        "        return True  # If customer doesn't provide, skip\n",
        "    cust = str(cust_val).strip().upper()\n",
        "    src = str(src_val).strip().upper()\n",
        "    return cust == src"
      ],
      "metadata": {
        "id": "0zKDqAzUNGZ4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Master Sanction/PEP List**"
      ],
      "metadata": {
        "id": "cEXIgmGMNJM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "master_path = \"/content/drive/My Drive/Research/Data/testing_data.csv\"\n",
        "master_df = pd.read_csv(master_path)\n",
        "master_df.fillna(\"\", inplace=True)\n",
        "master_df['NAME'] = master_df['NAME'].astype(str).str.strip().str.upper()\n",
        "master_df['ALIAS'] = master_df['ALIAS'].astype(str).str.strip()\n",
        "master_df['BIRTH_DATE'] = master_df['BIRTH_DATE'].astype(str).str.strip()\n",
        "master_df['ID'] = master_df['ID'].astype(str).str.strip()\n",
        "master_df['NATIONALITY'] = master_df['NATIONALITY'].astype(str).str.strip()\n",
        "\n",
        "print(f\"Loaded master list: {len(master_df)} records\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWQ-zuBKNIE5",
        "outputId": "fe031d4e-4296-4618-8458-55038cea436a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded master list: 32 records\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Customer List (Update Path After Uploading File)**"
      ],
      "metadata": {
        "id": "2sals6Z-NSS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume you upload 'customer_list.xlsx' to Colab's /content/ folder\n",
        "customer_path = \"/content/drive/My Drive/Research/Data/customer/testing_data_cus_list.xlsx\"  # Update if different\n",
        "customer_df = pd.read_excel(customer_path)\n",
        "customer_df.fillna(\"\", inplace=True)\n",
        "customer_df['NAME'] = customer_df['NAME'].astype(str).str.strip().str.upper()\n",
        "customer_df['ALIAS'] = customer_df['ALIAS'].astype(str).str.strip() if 'ALIAS' in customer_df else \"\"\n",
        "customer_df['BIRTH_DATE'] = customer_df['BIRTH_DATE'].astype(str).str.strip() if 'BIRTH_DATE' in customer_df else \"\"\n",
        "customer_df['ID'] = customer_df['ID'].astype(str).str.strip() if 'ID' in customer_df else \"\"\n",
        "customer_df['NATIONALITY'] = customer_df['NATIONALITY'].astype(str).str.strip() if 'NATIONALITY' in customer_df else \"\"\n",
        "\n",
        "print(f\"Loaded customer list: {len(customer_df)} records\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LasQ5jugNPgS",
        "outputId": "1f2dbefa-b940-46a1-f1df-422f5c350312"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded customer list: 5 records\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perform Matching**"
      ],
      "metadata": {
        "id": "ZHTnkqpcNZR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ==========================================\n",
        "# 1. CONFIGURATION & SETUP\n",
        "# ==========================================\n",
        "# Display settings to see all columns\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "SIMILARITY_THRESHOLD = 0.50  # Minimum name similarity to consider\n",
        "RISK_THRESHOLD = 0.50        # Minimum risk score to save\n",
        "\n",
        "WEIGHTS = {\n",
        "    \"name\": 0.6,\n",
        "    \"dob\": 0.2,\n",
        "    \"nationality\": 0.1,\n",
        "    \"id\": 0.1\n",
        "}\n",
        "\n",
        "# ==========================================\n",
        "# 2. HELPER FUNCTIONS\n",
        "# ==========================================\n",
        "def safe_get(row, keys, default=\"\"):\n",
        "    \"\"\"Robustly fetch keys like CATEGORY/Category/Type.\"\"\"\n",
        "    for k in keys:\n",
        "        if k in row:\n",
        "            val = row[k]\n",
        "            if pd.notna(val) and str(val).strip():\n",
        "                return str(val).strip()\n",
        "    return default\n",
        "\n",
        "def safe_field_match(cust_val, src_val):\n",
        "    \"\"\"Checks exact match, ignoring case and scientific notation.\"\"\"\n",
        "    if not cust_val or not src_val:\n",
        "        return 0.0\n",
        "    # specific fix for ID scientific notation (e.g. 2E+11)\n",
        "    c_str = str(cust_val).strip().upper().replace(\".0\", \"\")\n",
        "    s_str = str(src_val).strip().upper().replace(\".0\", \"\")\n",
        "    if c_str == s_str:\n",
        "        return 1.0\n",
        "    return 0.0\n",
        "\n",
        "def birth_year_score(cust_years, src_years):\n",
        "    if not cust_years or not src_years:\n",
        "        return 0.0\n",
        "    if cust_years.intersection(src_years):\n",
        "        return 1.0\n",
        "    return 0.0\n",
        "\n",
        "# ==========================================\n",
        "# 3. MAIN MATCHING LOOP\n",
        "# ==========================================\n",
        "reports = []\n",
        "print(f\"Starting matching process for {len(customer_df)} customers against {len(master_df)} source records...\")\n",
        "\n",
        "for _, cust in customer_df.iterrows():\n",
        "    # 3a. Parse Customer Data\n",
        "    cust_name = cust.get(\"NAME\", \"\")\n",
        "    cust_alias = cust.get(\"ALIAS\", \"\")\n",
        "    cust_birth_years = extract_birth_year(cust.get(\"BIRTH_DATE\", \"\"))\n",
        "    cust_id = cust.get(\"ID\", \"\")\n",
        "    cust_nat = cust.get(\"NATIONALITY\", \"\")\n",
        "\n",
        "    best_match = None\n",
        "    best_risk = -1.0\n",
        "    best_details = {}\n",
        "\n",
        "    # 3b. Iterate Master List\n",
        "    for _, src in master_df.iterrows():\n",
        "        src_id = src.get(\"ID\", \"\")\n",
        "\n",
        "        # --- SCORE CALCULATION ---\n",
        "\n",
        "        # 1. NAME CHECK\n",
        "        sims = {\"NAME\": get_similarity(cust_name, src.get(\"NAME\", \"\"))}\n",
        "        if \"ALIAS\" in src and pd.notna(src[\"ALIAS\"]):\n",
        "            sims[\"ALIAS\"] = get_similarity(cust_name, src[\"ALIAS\"])\n",
        "        if cust_alias:\n",
        "            sims[\"CUST_ALIAS\"] = get_similarity(cust_alias, src.get(\"NAME\", \"\"))\n",
        "\n",
        "        # Find best name score and which field matched\n",
        "        name_match_type, name_score = max(sims.items(), key=lambda x: x[1])\n",
        "\n",
        "        # 2. ATTRIBUTE CHECKS\n",
        "        src_birth_years = extract_birth_year(src.get(\"BIRTH_DATE\", \"\"))\n",
        "        dob_score = birth_year_score(cust_birth_years, src_birth_years)\n",
        "        nat_score = safe_field_match(cust_nat, src.get(\"NATIONALITY\", \"\"))\n",
        "        id_score = safe_field_match(cust_id, src_id)\n",
        "\n",
        "        # 3. DETERMINE FINAL MATCH REASON (Priority Logic)\n",
        "        final_reason = name_match_type  # Default\n",
        "        if id_score == 1.0:\n",
        "            final_reason = \"ID_MATCH\"\n",
        "        elif dob_score == 1.0 and name_score >= SIMILARITY_THRESHOLD:\n",
        "            final_reason = f\"{name_match_type}_AND_DOB\"\n",
        "\n",
        "        # 4. CALCULATE RISK\n",
        "        current_risk_score = (\n",
        "            name_score * WEIGHTS[\"name\"] +\n",
        "            dob_score * WEIGHTS[\"dob\"] +\n",
        "            nat_score * WEIGHTS[\"nationality\"] +\n",
        "            id_score * WEIGHTS[\"id\"]\n",
        "        )\n",
        "\n",
        "        # Force High Risk for ID Match\n",
        "        if id_score == 1.0:\n",
        "            current_risk_score = 1.0\n",
        "            confidence = \"CERTAIN\"\n",
        "        else:\n",
        "            match_count = sum([1 for s in [dob_score, nat_score, id_score] if s == 1.0])\n",
        "            if match_count >= 2 and name_score > 0.70:\n",
        "                confidence = \"VERY_HIGH\"\n",
        "            elif match_count >= 1 and name_score > 0.75:\n",
        "                confidence = \"HIGH\"\n",
        "            elif name_score > 0.80:\n",
        "                confidence = \"MEDIUM\"\n",
        "            else:\n",
        "                confidence = \"LOW\"\n",
        "\n",
        "        # 5. KEEP BEST MATCH\n",
        "        if current_risk_score > best_risk:\n",
        "            best_risk = current_risk_score\n",
        "            best_match = src\n",
        "            best_details = {\n",
        "                \"risk_score\": round(current_risk_score, 4),\n",
        "                \"confidence\": confidence,\n",
        "                \"match_reason\": final_reason,\n",
        "                \"score_name\": name_score,\n",
        "                \"score_dob\": dob_score,\n",
        "                \"score_nat\": nat_score,\n",
        "                \"score_id\": id_score\n",
        "            }\n",
        "\n",
        "    # 3c. Save Record if Threshold Met\n",
        "    if best_match is not None and (best_details[\"risk_score\"] >= RISK_THRESHOLD or best_details[\"score_id\"] == 1.0):\n",
        "\n",
        "        # Get Source Info\n",
        "        src_cat = safe_get(best_match, [\"CATEGORY\", \"Category\", \"TYPE\", \"Type\"], \"Unknown\").upper()\n",
        "        src_ds = safe_get(best_match, [\"DATASET\", \"Dataset\", \"SOURCE\", \"Source\"], \"Unknown\").upper()\n",
        "\n",
        "        reports.append({\n",
        "            \"customer_name\": cust_name,\n",
        "            \"source_name\": best_match.get(\"NAME\", \"\"),\n",
        "            \"TYPE\": src_cat,\n",
        "            \"SOURCE_LIST\": src_ds,\n",
        "\n",
        "            \"status\": \"HIT\" if best_details[\"risk_score\"] >= 0.7 else \"REVIEW\",\n",
        "            \"risk_score\": best_details[\"risk_score\"],\n",
        "            \"confidence\": best_details[\"confidence\"],\n",
        "            \"match_reason\": best_details[\"match_reason\"],\n",
        "\n",
        "            # RAW SCORES\n",
        "            \"SCORE_NAME\": f\"{best_details['score_name']*100:.1f}%\",\n",
        "            \"SCORE_DOB\": f\"{best_details['score_dob']*100:.1f}%\",\n",
        "            \"SCORE_NAT\": f\"{best_details['score_nat']*100:.1f}%\",\n",
        "            \"SCORE_ID\": f\"{best_details['score_id']*100:.1f}%\",\n",
        "\n",
        "            # Metadata\n",
        "            \"customer_id\": cust_id,\n",
        "            \"source_id\": best_match.get(\"ID\", \"\")\n",
        "        })\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2qneM0NZGvw",
        "outputId": "f0a2c982-6461-4d0e-f43f-5b11c924b795"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting matching process for 5 customers against 32 source records...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate and Save Report**"
      ],
      "metadata": {
        "id": "Hron3sPqNguJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #==========================================\n",
        "# 4. SUMMARY REPORTING\n",
        "# ==========================================\n",
        "if reports:\n",
        "    report_df = pd.DataFrame(reports)\n",
        "\n",
        "    # Define clean column order\n",
        "    cols_order = [\n",
        "        \"customer_name\", \"source_name\", \"TYPE\", \"SOURCE_LIST\",\n",
        "        \"status\", \"risk_score\", \"confidence\", \"match_reason\",\n",
        "        \"SCORE_NAME\", \"SCORE_DOB\", \"SCORE_NAT\", \"SCORE_ID\"\n",
        "    ]\n",
        "    # Filter columns\n",
        "    final_cols = [c for c in cols_order if c in report_df.columns] + \\\n",
        "                 [c for c in report_df.columns if c not in cols_order]\n",
        "    report_df = report_df[final_cols]\n",
        "\n",
        "    # --- PRINT SUMMARY ---\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"MATCHING SUMMARY STATISTICS\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"Total Hits Found: {len(report_df)}\")\n",
        "\n",
        "    print(\"\\n[1] Breakdown by Match Reason:\")\n",
        "    print(report_df['match_reason'].value_counts())\n",
        "\n",
        "    print(\"\\n[2] Breakdown by Confidence:\")\n",
        "    print(report_df['confidence'].value_counts())\n",
        "\n",
        "    print(\"\\n[3] Breakdown by Category (Sanction/PEP):\")\n",
        "    print(report_df['TYPE'].value_counts())\n",
        "\n",
        "    # Save\n",
        "    save_path = '/content/drive/My Drive/Research/Data/customer/sanction_check_report.csv'\n",
        "    report_df.to_csv(save_path, index=False)\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"Full report saved to: {save_path}\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Show preview\n",
        "    print(\"\\nPreview of Top Matches:\")\n",
        "    print(report_df.head(5))\n",
        "\n",
        "else:\n",
        "    print(\"\\nNo matches found above the threshold.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0RdVMU7rPlD",
        "outputId": "fe7aa7cd-e2fb-4196-961d-f2c5a5850aad"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "MATCHING SUMMARY STATISTICS\n",
            "==================================================\n",
            "Total Hits Found: 5\n",
            "\n",
            "[1] Breakdown by Match Reason:\n",
            "match_reason\n",
            "NAME        3\n",
            "ID_MATCH    2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "[2] Breakdown by Confidence:\n",
            "confidence\n",
            "HIGH       3\n",
            "CERTAIN    2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "[3] Breakdown by Category (Sanction/PEP):\n",
            "TYPE\n",
            "SANCTION    3\n",
            "PEP         2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "==================================================\n",
            "Full report saved to: /content/drive/My Drive/Research/Data/customer/sanction_check_report.csv\n",
            "==================================================\n",
            "\n",
            "Preview of Top Matches:\n",
            "                               customer_name                                source_name      TYPE   SOURCE_LIST  status  risk_score confidence match_reason SCORE_NAME SCORE_DOB SCORE_NAT SCORE_ID   customer_id     source_id\n",
            "0  DEEGODA GAMAGEI CHAMINDU DENUWAN RASHMIKA  DEEGODA GAMAGEI CHAMINDU DENUWAN RASHMIKA  SANCTION  TESTING_DATA     HIT      1.0000    CERTAIN     ID_MATCH     100.0%      0.0%    100.0%   100.0%  200221302925  200221302925\n",
            "1                     CHARUKA BANDARA DANAKA                   CHARUKA BANDARA DAHANAKA  SANCTION  TESTING_DATA  REVIEW      0.6983       HIGH         NAME      99.7%      0.0%    100.0%     0.0%                            \n",
            "2                               A H B K SAMA                           A H B K SAMANTHA       PEP  TESTING_DATA  REVIEW      0.6820       HIGH         NAME      97.0%      0.0%    100.0%     0.0%                            \n",
            "3                      W. M. CHATHURA DESHAN                      W. M. CHATHURA DESHAN  SANCTION  TESTING_DATA     HIT      0.7000       HIGH         NAME     100.0%      0.0%    100.0%     0.0%                            \n",
            "4                     K. G. N. PRIYADARSHNEE                     K. G. N. PRIYADARSHANI       PEP  TESTING_DATA     HIT      1.0000    CERTAIN     ID_MATCH      98.1%      0.0%    100.0%   100.0%    886543102V    886543102V\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if reports:\n",
        "#     report_df = pd.DataFrame(reports)\n",
        "#     report_df.to_csv('/content/drive/My Drive/Research/Data/customer/sanction_check_report.csv', index=False)\n",
        "#     print(\"\\n--- SANCTION/PEP MATCH SUMMARY ---\")\n",
        "#     print(report_df)\n",
        "#     print(\"\\nReport saved to: /content/sanction_check_report.csv\")\n",
        "# else:\n",
        "#     print(\"\\nNo matches found for any customers.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQATPTaRNh3q",
        "outputId": "3af8c6e2-a4f9-40a4-da4a-59aee53cb34b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- SANCTION/PEP MATCH SUMMARY ---\n",
            "                               customer_name  \\\n",
            "0  DEEGODA GAMAGEI CHAMINDU DENUWAN RASHMIKA   \n",
            "1                     CHARUKA BANDARA DANAKA   \n",
            "2                               A H B K SAMA   \n",
            "3                      W. M. CHATHURA DESHAN   \n",
            "4                     K. G. N. PRIYADARSHNEE   \n",
            "\n",
            "                                 source_name  status SCORE_NAME SCORE_DOB  \\\n",
            "0  DEEGODA GAMAGEI CHAMINDU DENUWAN RASHMIKA     HIT     100.0%      0.0%   \n",
            "1                   CHARUKA BANDARA DAHANAKA  REVIEW      99.7%      0.0%   \n",
            "2                           A H B K SAMANTHA  REVIEW      97.0%      0.0%   \n",
            "3                      W. M. CHATHURA DESHAN  REVIEW     100.0%      0.0%   \n",
            "4                     K. G. N. PRIYADARSHANI     HIT      98.1%      0.0%   \n",
            "\n",
            "  SCORE_NAT SCORE_ID  risk_score confidence   customer_id     source_id  \\\n",
            "0    100.0%   100.0%      1.0000    CERTAIN  200221302925  200221302925   \n",
            "1    100.0%     0.0%      0.6983       HIGH                               \n",
            "2    100.0%     0.0%      0.6820       HIGH                               \n",
            "3    100.0%     0.0%      0.7000       HIGH                               \n",
            "4    100.0%   100.0%      1.0000    CERTAIN    886543102V    886543102V   \n",
            "\n",
            "  customer_dob  source_dob  \n",
            "0   2002-07-31  31/07/2002  \n",
            "1   2002-10-18  18/10/2002  \n",
            "2   1994-10-25  25/10/1994  \n",
            "3   1994-04-12  12/04/1994  \n",
            "4          NaT              \n",
            "\n",
            "Report saved to: /content/sanction_check_report.csv\n"
          ]
        }
      ]
    }
  ]
}